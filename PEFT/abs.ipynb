{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff1596c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fa56d883fd4df2bb09773fb255bf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login,login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ef85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device='cuda'\n",
    "model_name_or_path='bigscience/bloomz-7b1'\n",
    "tokenizer_name_or_path='bigscience/bloomz-7b1'\n",
    "dataset_name='twitter_complaints'\n",
    "text_column='Tweet text'\n",
    "label_column='text_label'\n",
    "max_length=64\n",
    "lr=1e-3\n",
    "num_epochs=50\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b38a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unlabeled', 'complaint', 'no complaint']\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Tweet text', 'ID', 'Label', 'text_label'],\n",
      "        num_rows: 3399\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job',\n",
       " 'ID': 0,\n",
       " 'Label': 2,\n",
       " 'text_label': 'no complaint'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ought/raft\", dataset_name)\n",
    "# Get label names and replace underscore with spaces\n",
    "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
    "\n",
    "# Map label IDs to label names\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "print(dataset)\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288eb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a591c4bb9ec948a69dffceb144436a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/223 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ombha\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ombha\\.cache\\huggingface\\hub\\models--bigscience--bloomz-7b1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0f7a6f6bc148e8b6ae465c40b902c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58681dcd140541529b6806c2743ac65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ee99eac85b4fac81e6a8dd2ebe246b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf8a21c5fd4a38b0daffb96ccf3a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Preprocessing \n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "# Ensuring pad_token_id is defined\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id=tokenizer.eos_token_id\n",
    "target_max_length=max([len(tokenizer(class_label)['input_ids'])for class_label in classes])\n",
    "print(target_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    batch_size=len(examples[text_column])\n",
    "    inputs=[f\"{text_column}:{x} Label :\" for x in examples[text_column]]\n",
    "    targets=[str(x) for x in examples[label_column]]\n",
    "    model_inputs=tokenizer(inputs)\n",
    "    labels=tokenizer(targets, add_special_tokens=False)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids=model_inputs['input_ids'][i]\n",
    "        label_input_ids=labels['input_ids'][i] + [tokenizer.eos_token_id]\n",
    "        # Append Targets to inputs\n",
    "        model_inputs['input_ids'][i]= sample_input_ids + label_input_ids\n",
    "        # Prepare the training labels\n",
    "        labels['input_ids'][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs['attention_mask'][i]=[1] * len(model_inputs['input_ids'][i])\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "train_dataset = processed_datasets[\"train\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd21621b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713df1d9974e43b696fb8505150c20cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d8d1cf75c846798be338c452ff34aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ombha\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3, 227985,   5484,    915,   2566, 169403,  15296,  36272,\n",
      "            525,   3928,   1119,    632,   2670,   3968,  15270,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3, 227985,   5484,    915,   2566,  88653,   2321, 144017, 138861,\n",
      "          59283,   1152,    613,   2632,  12120,      4,   5673,   1152,  32153,\n",
      "            427,  36992,     15,   1152,   1400,   5065, 114438,  66455,    919,\n",
      "            404, 146304,  14078,  87856,   7061,   2906,     17,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
      "            915,   5673,    473,  11229,   2213,   2670,  35307,  28629,    461,\n",
      "           2566,   2765,   1531,   3470,  47134,  10144,   2765,   1531,    427,\n",
      "           2909,  17918,   6782,  27268,   4390,   1517,     17,   3904,    632,\n",
      "            267,   6497,    483,    361,   2670, 101848,     17,  32465,   9585,\n",
      "           2566,     37,   2481,   2566,     37,   2481,  12384,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3, 227985,\n",
      "           5484,    915,   2566,  15157,   4867,  14731, 165189,   2021,    769,\n",
      "          11528,   7220,  35025,    530,  27937, 149533,   1965,  43435, 163255,\n",
      "           1141,   3611,     17,  30655,    632,   1119,     17,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
      "            915,  35673,   8562,  29826, 102530,     15,   1427, 207595,     17,\n",
      "            915,     12,   2550,  81623,  14282,   5715,  37623,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "         227985,   5484,    915,   2566,     80,  11010,    905, 200058,   3904,\n",
      "           9746,   3370,    722,   1074,     15,   1965,    600,  50713, 191765,\n",
      "           4973,     34, 200008, 123467,   1306,   1427,  16198,   3262,  11700,\n",
      "          35237,  12602,   1293,   8398,    530,   1999,   4346,  87843,     17,\n",
      "           1594,  35367, 241792, 130376,    894,   3143,     42,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
      "             60,  80772,   1400,   1701,   2213,    368,  12171,  67777,    613,\n",
      "            267,  18210,  76252,    375,    916,   6635,   1320,   3776,    934,\n",
      "          44805,   1965,  13002,    934,     17,     21,     12,    791,    727,\n",
      "           1701,   2971,    267,  35307,  20845,  10172,     34,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3, 227985,\n",
      "           5484,    915,   2566,  96186,  29756,    351,    473,   1542,    654,\n",
      "           9322,    530,    368,  21851,    632,   6644,    530,  48132,     17,\n",
      "           6728,   1152,    727,   7747,   3638,   1119,     34,  77658,    915,\n",
      "            210]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "         227985,   5484,    915,   2566,  74757,  64626,  12384,  44639,    613,\n",
      "          52282,   2670,  79920,   3344,   1002,    368,  17646,  14472,   8348,\n",
      "            664,    718,      4,  19036,     17,  31849,     17,   6312,     76,\n",
      "             44,  62470,     56,     91,     50,  14839,     21,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3, 227985,   5484,    915,    405, 187059,\n",
      "           2256,    664,   2550,  18833,  18607, 162467,      4,   1387,   6199,\n",
      "           3291,  23405,    613,   4657,  17082,    566,   3432,    368,  78851,\n",
      "           1185,  61273,  23181,   1553,  15596,    212, 116057,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3, 227985,   5484,\n",
      "            915,  39762,   2566,  22253,   6201,  75701,     15,    632,    718,\n",
      "           5840,  10006,   6201,  18881,    427,   3804,  19528,    267, 158974,\n",
      "           1320,    368,  10029,    632,  49666,     92,     34,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3, 227985,   5484,    915,   2566, 104565,   8695,   2089,   6140,\n",
      "         109676,  99579,   1369,    512,    368,   4570,     54,    632,    368,\n",
      "           1503, 241485, 132226,     15,    982,    727,   1152,  18100,    861,\n",
      "          32596,  77597, 168154,   1306, 132226,   4346,  87843,     17, 130462,\n",
      "            364,  32923,     89,     53,   8309,     20,     75,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3, 227985,   5484,    915,   2566,\n",
      "          14173,   2960,  29906,    387,  20706,  49337,   1369,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3, 227985,   5484,    915,   2566, 219553,  45736,\n",
      "          36876,   1713,     72,    707, 187205,  13002, 177324,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3, 227985,   5484,    915,   2566, 233938,  28518,  13716,\n",
      "            427,  28146,   1119,  17918,     17, 236706,    368, 214997,   7555,\n",
      "          48659,   5276,  21600,    343,     17,  51416,  22403,    318,   1531,\n",
      "           1306,   1130,  20934,    567, 101161, 184849,  87843,     17,   1594,\n",
      "          15231,   2052,  16642,     20,   7180,     80,     26,  77658,    915,\n",
      "            210],\n",
      "        [     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "              3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
      "         227985,   5484,    915,   2566,     80,   2068,    479,   2566,     80,\n",
      "           1376,    878, 147587,   3904,    632,    368,   6084,  65673,  78851,\n",
      "          11736,  15527,  19082,  33151,    461,     17,  45575,  17887,    632,\n",
      "           5219,  14216,  68870,   5967,   1841,   4346,  87843,     17,   1594,\n",
      "          14512,     27,     71,   8184,     19,    290,  63748,  77658,    915,\n",
      "            210]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "def test_preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    test_preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "eval_dataset = processed_datasets[\"train\"]\n",
    "test_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n",
    "print(next(iter(eval_dataloader)))\n",
    "print(next(iter(test_dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fff63ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The paging file is too small for this operation to complete. (os error 1455)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m peft_model_id = \u001b[33m\"\u001b[39m\u001b[33mOmBhandwalkar/twitter_complaints_bigscience_bloomz-7b1_LORA_CAUSAL_LM\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m config = PeftConfig.from_pretrained(peft_model_id)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model = PeftModel.from_pretrained(model, peft_model_id, device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, max_memory=max_memory)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ombha\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    568\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ombha\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:262\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    264\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ombha\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:4042\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4022\u001b[39m     resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n\u001b[32m   4023\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   4024\u001b[39m         resolved_archive_file,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4034\u001b[39m         _commit_hash=commit_hash,\n\u001b[32m   4035\u001b[39m     )\n\u001b[32m   4037\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4038\u001b[39m     is_safetensors_available()\n\u001b[32m   4039\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   4040\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file.endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4041\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m4042\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   4043\u001b[39m         metadata = f.metadata()\n\u001b[32m   4045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4046\u001b[39m         \u001b[38;5;66;03m# Assume it's a pytorch checkpoint (introduced for timm checkpoints)\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: The paging file is too small for this operation to complete. (os error 1455)"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "max_memory = {0: \"1GIB\", 1: \"1GIB\", 2: \"2GIB\", 3: \"10GIB\", \"cpu\": \"30GB\"}\n",
    "peft_model_id = \"OmBhandwalkar/twitter_complaints_bigscience_bloomz-7b1_LORA_CAUSAL_LM\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\", max_memory=max_memory)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map=\"auto\", max_memory=max_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7979191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c677ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "i=89\n",
    "\n",
    "inputs=tokenizer(f\"{text_column} : {dataset['test'][i]['Tweet text']} Label : \",return_tensors='pt')\n",
    "print(dataset['test'][i]['Tweet text'])\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs=model.generate(input_ids=inputs['input_ids'], max_new_tokens=10)\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(),skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
